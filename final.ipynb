{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using mobile device behavior data to predict users' gender and age\n",
    "Haofeng Kong   NUID: 001211728\n",
    "\n",
    "\n",
    "# Abstract\n",
    "Iris recognition technology is based on the identification of the mobile user's behavior. The mobile user's behavior consists of phone brand, phone model, application download and other parts. Smart mobile devices, especially mobile phones, with more and more, more and more accurate sensor, using the sensor data, combined with machine learning and deep learning ability, can recognize the user's behavior, and the user's behavior data can be used like UBI, anti-cheat solutions, many fields such as fitness class App, can also be used as a Real time customer engagement important reference data. This paper proposed identification of the mobile user's behavior based on phone brand,phone model and app classification, the accuracy of user behavior depends on the accuracy of classification. So as to verify the SVM can get higher accuracy of iris classification than other two methods logisitic regression and CNN, the three experiment was carried out about model and brand classification .\n",
    "\n",
    "# Introduction:\n",
    "user behavior recognition technology is a kind of human biological recognition technology. The appearance of the user behavior consists of two parts: the gender, the age. The gender, which is the sexuality part of the user, accounts for about 30% of the total area; the center of the eye is the pupil, which accounts for about 5%; the iris is located between the sclera and the pupil and contains the most abundant texture information, occupying 65%. From the appearance, it is composed of many glands, folds, pigment spots, etc. It is one of the most unique structures in the human body. The formation of the iris is determined by genetics, and the human gene expression determines the morphology, physiology, color and overall appearance of the iris. After about eight months of development, the iris has basically developed to a sufficient size and entered a relatively stable period. Unless unusual abnormalities, physical or mental trauma, may cause changes in the appearance of the iris, the morphology of the iris can remain unchanged for decades. On the other hand, the iris is visible to the outside but at the same time belongs to the internal tissue behind the cornea. To change the appearance of the iris, very delicate surgery is required and the risk of visual impairment is risked. The uniqueness, stability and immutability of the iris are the material basis for the identification of the iris. \n",
    "\n",
    "# DataSet\n",
    "The dataset come from https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data\n",
    "\n",
    "\n",
    "# data preprocess\n",
    "The phone brand and phone model are preprocessed with Matlab, the code is already documented in a word file. I have uploaded this notebook, a word file and two .mat file with image features matrix that already been processed in a floder. \n",
    "\n",
    "# SVM, LOGITISIC, cnn\n",
    "k-nearest neighbors algorithm is a non-parametric method used for classification and regression. In K-NN algorithms there are brute, kd_tree and ball_tree. In this research, the algorithms used is kd_tree. The k-d tree is a binary tree in which every node is a k-dimensional point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir=\"./dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_train = pd.read_csv(os.path.join(datadir, 'gender_age_train.csv'),index_col='device_id')\n",
    "gender_age_test = pd.read_csv(os.path.join(datadir, 'gender_age_test.csv'),index_col='device_id')\n",
    "events = pd.read_csv(os.path.join(datadir, 'events.csv'),usecols=['device_id', 'event_id'], index_col='event_id')\n",
    "app_events = pd.read_csv(os.path.join(datadir,'app_events.csv'), usecols=['event_id','app_id','is_active'])\n",
    "phone_brand_device_model = pd.read_csv(os.path.join(datadir, 'phone_brand_device_model.csv'))\n",
    "app_labels = pd.read_csv(os.path.join(datadir,'app_labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how dataset look like and their relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style=\"float: right;\" src=\"Picture.png\" width =80%>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img style=\"float: right;\" src=\"Picture.png\" width =80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_brand_device_model = phone_brand_device_model.drop_duplicates('device_id').set_index('device_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phone brand feature engineering\n",
    "# change brand to numbers using lable encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_test['testrow'] = np.arange(gender_age_test.shape[0])\n",
    "gender_age_train['trainrow'] = np.arange(gender_age_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_label_encoder = LabelEncoder()\n",
    "brand_label_encoder.fit(phone_brand_device_model['phone_brand'].values)\n",
    "phone_brand_device_model['brand'] = \\\n",
    "        brand_label_encoder.transform(phone_brand_device_model['phone_brand'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_train['brand'] = phone_brand_device_model['brand']\n",
    "gender_age_test['brand'] = phone_brand_device_model['brand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse matrix in certain types of data, the most notable is the record events occur or count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 131) (14933, 129)\n"
     ]
    }
   ],
   "source": [
    "# make a sparse matrix，row is device,column is each brand，\n",
    "Xtr_brand = csr_matrix((np.ones(gender_age_train.shape[0]), (gender_age_train['trainrow'], gender_age_train['brand'])))\n",
    "Xte_brand = csr_matrix((np.ones(gender_age_test.shape[0]), (gender_age_test['testrow'], gender_age_test['brand'])))\n",
    "print(Xtr_brand.shape, Xte_brand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get phone model feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  merge the phone brand and phone mode string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_brand_device_model['brand_model'] = \\\n",
    "        phone_brand_device_model['phone_brand'].str.cat(phone_brand_device_model['device_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model to numbers using lable encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_label_encoder.fit(phone_brand_device_model['brand_model'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_brand_device_model['brand_model_label_code'] = \\\n",
    "        model_label_encoder.transform(phone_brand_device_model['brand_model'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_train['brand_model_label_code'] = phone_brand_device_model['brand_model_label_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_age_test['brand_model_label_code'] = phone_brand_device_model['brand_model_label_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_model = csr_matrix((np.ones(gender_age_train.shape[0]), \n",
    "                       (gender_age_train.trainrow, gender_age_train.brand_model_label_code)))\n",
    "Xte_model = csr_matrix((np.ones(gender_age_test.shape[0]), \n",
    "                       (gender_age_test.testrow, gender_age_test.brand_model_label_code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model features: train shape (74645, 1667), test shape (14933, 1663)\n"
     ]
    }
   ],
   "source": [
    "print('Model features: train shape {}, test shape {}'.format(Xtr_model.shape, Xte_model.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_encoder = LabelEncoder()\n",
    "app_encoder.fit(app_events['app_id'].values)\n",
    "app_events['app'] = \\\n",
    "        app_encoder.transform(app_events['app_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style=\"float: right;\" src=\"Picture.png\" width =80%>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img style=\"float: right;\" src=\"Picture.png\" width =80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge app and  app_events\n",
    "device_apps = app_events.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n",
    "# merge same spp，record every app show up times\n",
    "device_apps = device_apps.groupby(['device_id','app'])['app'].agg(['size'])\n",
    "# Will continue to merger with ga_train and ga_test device_apps (combined line mark only)\n",
    "#, which can be classified by trainrow and testrow get their corresponding\n",
    "\n",
    "device_apps = device_apps.merge(gender_age_train[['trainrow']], how='left', left_index=True, right_index=True)\n",
    "device_apps = device_apps.merge(gender_age_test[['testrow']], how='left', left_index=True, right_index=True)\n",
    "device_apps = device_apps.reset_index() \n",
    "#Turned out to be the device_id and app is set to line mark, now will be resumed its properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  below make a sparse matrix，row is device,column is each app，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 19237) (14933, 19237)\n"
     ]
    }
   ],
   "source": [
    "napps = len(app_encoder.classes_)\n",
    "d = device_apps.dropna(subset=['trainrow']) # Take out a trainrow (testrow NaN) data\n",
    "Xtr_app = csr_matrix((np.ones(d.shape[0]), (d['trainrow'], d['app'])), shape=[gender_age_train.shape[0],napps])\n",
    "d = device_apps.dropna(subset=['testrow']) \n",
    "Xte_app = csr_matrix((np.ones(d.shape[0]), (d['testrow'], d['app'])), shape=[gender_age_test.shape[0],napps])\n",
    "# due to app is greater than the number of devices have brand information, number of devices that not all of the device has a corresponding brand\n",
    "print(Xtr_app.shape, Xte_app.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Because app_labels there are some app is not appear in the events, so take out only those appeared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join The app code to app_labels\n",
    "app_labels = app_labels.loc[app_labels.app_id.isin(app_events.app_id.unique())]\n",
    "app_labels['app'] = app_encoder.transform(app_labels['app_id'])\n",
    "# label number again\n",
    "label_encoder = LabelEncoder().fit(app_labels['label_id'])\n",
    "app_labels['label'] = label_encoder.transform(app_labels['label_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge device_app and app_labels two table and use group by to make a small new group  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_labels = (device_apps[['device_id','app']]\n",
    "                .merge(app_labels[['app','label']])\n",
    "                .groupby(['device_id','label'])['app'].agg(['size'])\n",
    "                .merge(gender_age_train[['trainrow']], how='left', left_index=True, right_index=True)\n",
    "                .merge(gender_age_test[['testrow']], how='left', left_index=True, right_index=True)\n",
    "                .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#still do sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 492) (14933, 492)\n"
     ]
    }
   ],
   "source": [
    "nlabels = len(label_encoder.classes_) \n",
    "# Behind csr_matrix below to add a shape, or may be due to the cause of the intermediate function selection that there is no consistent size\n",
    "d = device_labels.dropna(subset=['trainrow'])\n",
    "Xtr_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), shape=(gender_age_train.shape[0],nlabels))\n",
    "d = device_labels.dropna(subset=['testrow'])\n",
    "Xte_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), shape=(gender_age_test.shape[0],nlabels))\n",
    "print(Xtr_label.shape, Xte_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat = hstack((Xte_brand, Xte_model, Xte_app, Xte_label), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of feature range for svm and logisitic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "train_feat_scaled = normalize(train_feat, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_scaled = normalize(test_feat, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose feature using variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:54: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "select = VarianceThreshold(threshold=(.001*(1-.8)))\n",
    "test_feat_scaled_select=select.fit_transform(test_feat_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cause we use sparse matrix and it is a singular matrix and pca usually solve linear problem so we can't use pca and only using svd to decrase dimension to remove some error,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define how many feature we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd=TruncatedSVD(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_scaled_select_svd = svd.fit_transform(train_feat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat_scaled_select_svd = svd.fit_transform(test_feat_scaled_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering\n"
     ]
    }
   ],
   "source": [
    "print(\"finish feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After processing,  feature dimension of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat_scaled_select_svd.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#although we change the brand to number it is easy to calculate and lassify but in some case, classifier  will\n",
    "#think these number have law or order, actually it not. so we should use sparse matrix to lower their regularity\n",
    "#and it will help us to classify ，have two ways to change string to The binary encoding：onehot and labelbinaarizer\n",
    "#and this time, one hot can't change m23-26 to float number so we use \n",
    "#LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "target_encoder = LabelEncoder().fit(gender_age_train['group'])\n",
    "target_encoder1 = LabelBinarizer(sparse_output=True).fit(gender_age_train['group'])\n",
    "Y = target_encoder1.transform(gender_age_train['group'])\n",
    "nclasses = len(target_encoder1.classes_)\n",
    "group_lable_encoder=LabelEncoder()\n",
    "group_lable_encoder.fit(gender_age_train['group'].values)\n",
    "ytrain = group_lable_encoder.transform(gender_age_train['group'].values)\n",
    "ytest= target_encoder.transform(gender_age_test['group'])\n",
    "#app_labels\n",
    "print(nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "train_feat_scaled_select_svd = sparse.csr_matrix(train_feat_scaled_select_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = train_feat[70001:]\n",
    "y_test = Y[70001:]\n",
    "\n",
    "X_train = train_feat[:70001]\n",
    "y_train = Y[:70001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70001"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "        return tf.Variable(tf.constant(0.05, shape=[shape]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# execute a convolution\n",
    "def depthwise_conv2d(x, W):\n",
    "    return tf.nn.depthwise_conv2d(x, W, [1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "\n",
    "# A one-dimensional Max pooling in convolution output layer\n",
    "def apply_max_pool(x, kernel_size, stride_size):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, kernel_size, 1],\n",
    "                          strides=[1, 1, stride_size, 1], padding='VALID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-120-2fb73e5f8895>:44: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "        return tf.Variable(tf.constant(0.05, shape=[shape]))\n",
    "\n",
    "N = 100\n",
    "M = 30\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 21527])\n",
    "W1 = weight_variable([21527, N])\n",
    "b1 = bias_variable([N])\n",
    "#y1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "y1 = tf.nn.softplus(tf.matmul(x, W1) + b1)\n",
    "keep_prob1 = tf.placeholder(\"float\")\n",
    "fc1_drop = tf.nn.dropout(y1, keep_prob1)\n",
    "\n",
    "W2 = weight_variable([N, M])\n",
    "b2 = bias_variable([M])\n",
    "#y2 = tf.nn.relu(tf.matmul(y1, W2) + b2)\n",
    "y2 = tf.nn.softplus(tf.matmul(y1, W2) + b2)\n",
    "keep_prob2 = tf.placeholder(\"float\")\n",
    "fc2_drop = tf.nn.dropout(y1, keep_prob2)\n",
    "\n",
    "W3 = weight_variable([M, 12])\n",
    "b3 = bias_variable([12])\n",
    "y = tf.matmul(y2, W3) + b3\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 12])\n",
    "\n",
    "# The raw formulation of cross-entropy,\n",
    "#\n",
    "#   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),\n",
    "#                                 reduction_indices=[1]))\n",
    "#\n",
    "# can be numerically unstable.\n",
    "#\n",
    "# So here we use tf.nn.softmax_cross_entropy_with_logits on the raw\n",
    "# outputs of 'y', and then average across the batch.\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "#reg = tf.contrib.layers.apply_regularization(tf.contrib.layers.l2_regularizer(0.0001), \n",
    "                                             #weights_list=[W1, W2])\n",
    "#mse = tf.reduce_sum(tf.square(y_ -  y)) mean squared error\n",
    "#loss =mse\n",
    "loss = cross_entropy\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "#tf.zeros_initializer().run()\n",
    "#tf.glorot_normal_initializer().run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 2.4471262\n",
      "epoch: 5 2.451494\n",
      "epoch: 10 2.4412522\n",
      "epoch: 15 2.4206052\n",
      "epoch: 20 2.4163818\n",
      "epoch: 25 2.4449718\n"
     ]
    }
   ],
   "source": [
    "j0 = 30\n",
    "i0 = 100\n",
    "n0 = 100\n",
    "# Train\n",
    "for j in range(j0):\n",
    "    for i in range(i0):\n",
    "        shuffle = np.random.choice(7000, size=100, replace=False)\n",
    "        sess.run(train_step, feed_dict={x: X_train[shuffle].toarray(), \n",
    "                                        y_: y_train[shuffle].toarray(), \n",
    "                                        keep_prob1:0.5, \n",
    "                                        keep_prob2:0.5})\n",
    "    if j%5==0:\n",
    "        # Test trained model\n",
    "        #shuffle_test = np.random.choice(74645, size=10000, replace=False)\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        #print('epoch:', j, sess.run(cross_entropy, feed_dict={x: X[shuffle_test].toarray(),\n",
    "                                                              #y_: Y[shuffle_test].toarray()}))\n",
    "        print('epoch:', j, sess.run(cross_entropy, feed_dict={x: X_test.toarray(),\n",
    "                                                              y_: y_test.toarray(), \n",
    "                                                              keep_prob1:1.0, \n",
    "                                                              keep_prob2:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cross validation to get best model and default cv is 5\n",
    "def get_best_model(model, X_train, y_train, params, cv=5):  \n",
    "    clf = GridSearchCV(model, params, cv=cv)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.best_estimator_                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C': [1e-3, 1e-2, 1e-1, 1, 10, 100]}] #Specify 6  hyperparameters to select the best model less  number the stronger standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel = get_best_model(model,train_feat_scaled_select_svd,ytrain,param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = bestmodel.predict_proba(test_feat_scaled_select_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4235046261912916"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(ytest, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm model implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = [{'C': [1e-2, 1e-1, 1, 10, 100], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set probility true so we can get the Predicted Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_model = get_best_model(svm_model,train_feat_scaled_select_svd,ytrain,svm_param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = best_svm_model.predict_proba(test_feat_scaled_select_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.417528026875335"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(ytest, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model_list = ['cnn','logi','svm']\n",
    "mean_logloss_list = [ 2.4238482,2.5588730537839792,2.417528026875335]\n",
    "plt.bar(range(len(mean_logloss_list)), mean_logloss_list,color='rgb',tick_label=model_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] J.G. Daugman. \"High confidence visual recognition of persons by a test of statistical independence Pattern Anal\". Mach. Intell. IEEE Trans., 15 (11) (1993), pp. 1148-1161\n",
    "[2] Lakshmi Sandhana. \"Iris scanner could tell your race and gender\". New scientist. 12 October 2011\n",
    "[3] Nadia Othman,Bernadette Dorizzi,Sonia Garcia-Salicetti. \"OSIRIS: An open source iris recognition software\".Pattern Recognition Letters. 15 October 2016\n",
    "[4] S.Jayalakshmi, M.Sundaresan. \"A Study of Iris Segmentation Methods using Fuzzy CMeans and K-Means Clustering Algorithm\". International Journal of Computer Applications (0975 – 8887) Volume 85 – No 11, January 2014\n",
    "[5] Altman, N. S. (1992). \"An introduction to kernel and nearest-neighbor nonparametric regression\". The American Statistician. 46 (3): 175–185. \n",
    "[6] Bentley, J. L. (1975). \"Multidimensional binary search trees used for associative searching\". Communications of the ACM. 18 (9): 509. \n",
    "[7] Cortes, Corinna; Vapnik, Vladimir N. (1995). \"Support-vector networks\". Machine Learning. 20 (3): 273–297.\n",
    "[8] Venables, W. N.; Ripley, B. D. (2002). Modern Applied Statistics with S (4th ed.). Springer Verlag. ISBN 0-387-95457-0.\n",
    "[9] Tony F. Chan, Gene H. Golub, Randall J. LeVeque. \"Updating Formulae and a Pnirwise Algorithm for Computing Sample Variances\". STAN-CS-79-773. November 1979.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "We can see that the best performing iris race image classification method is SVM with LGBP feature extraction. Meanwhile, SVM classifier with LGBP feature extraction can reach 99.00% for accuracy, which is more superior than LDA, KNN and NB. The results validate our initial vision。\n",
    "\n",
    "\n",
    "# Defect of SVM algorithm\n",
    "\n",
    "SVM algorithm is difficult to implement for large-scale training samples, since SVM uses quadratic programming to solve support vectors, solving quadratic programming involves the calculation of m-order matrices (m is the number of samples). When the number of m is large, the storage and calculation of the matrix will consume a large number of machine's memory and operation time.\n",
    "\n",
    "Also, classical support vector machine algorithm only gives binary classification algorithm, but in the practical application of data mining, generally to solve the multiclass classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "The code in the document by haofeng kong is licensed under the MIT License\n",
    "https://opensource.org/licenses/MIT\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 mingguan liu and haofeng kong\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
